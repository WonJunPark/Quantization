{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "qtorch_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4dc1be009e844b687a5e359a2280d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5787257dac974beaab388ec62a7e84b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db733677c6d745c9bea11518d6549c87",
              "IPY_MODEL_adfc13eda4b54810bc4394ef20cf7caf"
            ]
          }
        },
        "5787257dac974beaab388ec62a7e84b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db733677c6d745c9bea11518d6549c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0980e4b4f2841a9b8dba4239fadd783",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce37afcf85fe4a9dada20955d68d08da"
          }
        },
        "adfc13eda4b54810bc4394ef20cf7caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b6dc19f005b4284ba8bc8f22de43144",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:06&lt;00:00, 27260847.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76b10c4f03914e08837e7ab1a9749f12"
          }
        },
        "f0980e4b4f2841a9b8dba4239fadd783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce37afcf85fe4a9dada20955d68d08da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b6dc19f005b4284ba8bc8f22de43144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76b10c4f03914e08837e7ab1a9749f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WonJunPark/Quantization/blob/main/qtorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVxD1R3y-iKP",
        "outputId": "aeff93ef-1f07-4cfc-e019-009ca62961e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Tiiiger/QPyTorch.git\n",
        "\n",
        "!pip install torchvision tqdm ninja\n",
        "\n",
        "!pip install -r QPyTorch/requirements.txt\n",
        "\n",
        "!pip install qtorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'QPyTorch'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (133/133), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 1415 (delta 53), reused 66 (delta 33), pack-reused 1282\u001b[K\n",
            "Receiving objects: 100% (1415/1415), 279.45 KiB | 5.82 MiB/s, done.\n",
            "Resolving deltas: 100% (861/861), done.\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Collecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision) (0.16.0)\n",
            "Installing collected packages: ninja\n",
            "Successfully installed ninja-1.10.0.post2\n",
            "Requirement already satisfied: sphinx>=1.4 in /usr/local/lib/python3.6/dist-packages (from -r QPyTorch/requirements.txt (line 1)) (1.8.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r QPyTorch/requirements.txt (line 2)) (4.10.1)\n",
            "Collecting nbsphinx\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/7a/9828e8981e472e717f695da957f52b389e91086532797005999342f487b5/nbsphinx-0.8.0-py3-none-any.whl\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2.11.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (0.16)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (50.3.2)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (1.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (20.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r QPyTorch/requirements.txt (line 2)) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r QPyTorch/requirements.txt (line 2)) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r QPyTorch/requirements.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r QPyTorch/requirements.txt (line 2)) (5.3.5)\n",
            "Requirement already satisfied: nbconvert!=5.4 in /usr/local/lib/python3.6/dist-packages (from nbsphinx->-r QPyTorch/requirements.txt (line 3)) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from nbsphinx->-r QPyTorch/requirements.txt (line 3)) (5.0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (1.1.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx>=1.4->-r QPyTorch/requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (0.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r QPyTorch/requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r QPyTorch/requirements.txt (line 2)) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r QPyTorch/requirements.txt (line 2)) (4.6.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (2.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->-r QPyTorch/requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert!=5.4->nbsphinx->-r QPyTorch/requirements.txt (line 3)) (0.5.1)\n",
            "Installing collected packages: nbsphinx\n",
            "Successfully installed nbsphinx-0.8.0\n",
            "Collecting qtorch\n",
            "  Downloading https://files.pythonhosted.org/packages/60/0e/93736b65669268f94f0d76edf72b49b949f9778fcd0e0098619ae08439ad/qtorch-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from qtorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.5.0->qtorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.5.0->qtorch) (0.16.0)\n",
            "Installing collected packages: qtorch\n",
            "Successfully installed qtorch-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Ma9iN1-dQf"
      },
      "source": [
        "# 3. CIFAR-10 tutorial - Inference, trans-precision\n",
        "\n",
        "# import useful modules\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from qtorch.quant import Quantizer, quantizer\n",
        "from qtorch.optim import OptimLP\n",
        "from torch.optim import SGD\n",
        "from qtorch import FloatingPoint\n",
        "from tqdm import tqdm\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOLu7dF7-dQj",
        "outputId": "7a206992-b859-4356-f25a-23b237203e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "e4dc1be009e844b687a5e359a2280d84",
            "5787257dac974beaab388ec62a7e84b0",
            "db733677c6d745c9bea11518d6549c87",
            "adfc13eda4b54810bc4394ef20cf7caf",
            "f0980e4b4f2841a9b8dba4239fadd783",
            "ce37afcf85fe4a9dada20955d68d08da",
            "2b6dc19f005b4284ba8bc8f22de43144",
            "76b10c4f03914e08837e7ab1a9749f12"
          ]
        }
      },
      "source": [
        "# loading data\n",
        "ds = torchvision.datasets.CIFAR10\n",
        "path = os.path.join(\"./data\", \"CIFAR10\")\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "test_set = ds(path, train=False, download=True, transform=transform_test)\n",
        "loaders = {\n",
        "        'test': torch.utils.data.DataLoader(\n",
        "            test_set,\n",
        "            batch_size=128,\n",
        "            num_workers=4,\n",
        "            pin_memory=True\n",
        "        )\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4dc1be009e844b687a5e359a2280d84",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/CIFAR10/cifar-10-python.tar.gz to ./data/CIFAR10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKUBBX7R-dQo"
      },
      "source": [
        "# define two floating point formats\n",
        "bit_8 = FloatingPoint(exp=5, man=2)\n",
        "bit_16 = FloatingPoint(exp=6, man=9)\n",
        "\n",
        "# define quantization functions\n",
        "weight_quant = quantizer(forward_number=bit_8,\n",
        "                        forward_rounding=\"nearest\")\n",
        "grad_quant = quantizer(forward_number=bit_8,\n",
        "                        forward_rounding=\"nearest\")\n",
        "momentum_quant = quantizer(forward_number=bit_16,\n",
        "                        forward_rounding=\"stochastic\")\n",
        "acc_quant = quantizer(forward_number=bit_16,\n",
        "                        forward_rounding=\"stochastic\")\n",
        "\n",
        "# define a lambda function so that the Quantizer module can be duplicated easily\n",
        "act_error_quant = lambda : Quantizer(forward_number=bit_8, backward_number=bit_8,\n",
        "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug46JN3S-dQr",
        "outputId": "a3b74fbd-8dbd-459f-d8d8-1d6d49dac4e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define model\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, quant, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.quant = quant()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.quant(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.quant(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.quant(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.quant(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        return out\n",
        "    \n",
        "class PreResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,quant, num_classes=10, depth=20):\n",
        "\n",
        "        super(PreResNet, self).__init__()\n",
        "        assert (depth - 2) % 6 == 0, 'depth should be 6n+2'\n",
        "        n = (depth - 2) // 6\n",
        "\n",
        "        block = BasicBlock\n",
        "\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.layer1 = self._make_layer(block, 16, n, quant)\n",
        "        self.layer2 = self._make_layer(block, 32, n, quant, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, n, quant, stride=2)\n",
        "        self.bn = nn.BatchNorm2d(64 * block.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "        self.quant = quant()\n",
        "        IBM_half = FloatingPoint(exp=6, man=9)\n",
        "        self.quant_half = Quantizer(IBM_half, IBM_half, \"nearest\", \"nearest\")\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, quant, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "            )\n",
        "\n",
        "        layers = list()\n",
        "        layers.append(block(self.inplanes, planes, quant , stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, quant))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant_half(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.quant(x)\n",
        "\n",
        "        x = self.layer1(x)  # 32x32\n",
        "        x = self.layer2(x)  # 16x16\n",
        "        x = self.layer3(x)  # 8x8\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.quant(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.quant_half(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d9AWYGd_QWJ"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUKUBMAj-dQt"
      },
      "source": [
        "model = PreResNet(act_error_quant)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEzgmFUA_DQd",
        "outputId": "0de11fae-8f3d-47a4-cfec-db7b1ebe1c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  QPyTorch\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFUt7NpG-dQw",
        "outputId": "ad071133-82f5-4c25-d5ac-03ef61d6afef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# pth파일 불러와야됨\n",
        "checkpoint = torch.load('PreResNet_fp32.pth')\n",
        "model.load_state_dict(checkpoint['model'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdbqtOnb-dQz"
      },
      "source": [
        "device = 'cuda' # change device to 'cuda' if you want to run this example on cuda\n",
        "model = model.to(device=device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL0uFc34-dQ3"
      },
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
        "optimizer = OptimLP(optimizer,\n",
        "                    weight_quant=weight_quant,\n",
        "                    grad_quant=grad_quant,\n",
        "                    momentum_quant=momentum_quant,\n",
        "                    acc_quant=acc_quant,\n",
        "                    grad_scaling=1/1000 # do loss scaling\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDW7KhL1-dQ6"
      },
      "source": [
        "def run_epoch(loader, model, criterion, optimizer=None):\n",
        "    loss_sum = 0.0\n",
        "    correct = 0.0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    ttl = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
        "            input = input.to(device=device)\n",
        "            target = target.to(device=device)\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            loss_sum += loss.cpu().item() * input.size(0)\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            ttl += input.size()[0]\n",
        "\n",
        "    correct = correct.cpu().item()\n",
        "    return {\n",
        "        'loss': loss_sum / float(ttl),\n",
        "        'accuracy': correct / float(ttl) * 100.0,\n",
        "    }"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzILRbuI-dQ8",
        "outputId": "8082c2d3-05ca-42e0-9707-891230f80bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_res = run_epoch(loaders['test'], model, F.cross_entropy, optimizer=optimizer)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 36.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kID_edlV-dQ_",
        "outputId": "a936220b-087d-4538-9b17-a26755b4f68f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_res"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 92.03, 'loss': 0.26623555870056154}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5d4Fx9C-dRD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}